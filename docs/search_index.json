[["index.html", "NonParametric Stats 1 Hypothesis Testing", " NonParametric Stats Katherine Wilson 2022-04-27 1 Hypothesis Testing \\[\\begin{equation} X \\sim N(\\mu,\\sigma^2), f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma}}e-\\frac{(x-\\mu)^2}{2\\sigma^2}, F(x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi\\sigma}}e\\frac{-(t-\\mu)^2}{2\\sigma^2}dt \\end{equation}\\] Normal Distributions a =0 b=1 lx=100 x=seq(-4,4,length=lx) fx = dnorm(x,a,b) bx = 1 dbx=dnorm(bx,a,b) dbx ## [1] 0.2419707 plot(x,fx, type = &quot;l&quot;, xlab = &quot;x&quot;, ylab = &quot;f(x)&quot;, main = &quot;Normal density functions&quot;, las= 1) dist_2 &lt;- dnorm(x, mean=0, sd=4) dist_3 &lt;- dnorm(x, mean=1, sd=1) dist_4 &lt;- dnorm(x, mean=1, sd =4) lines(x, dist_2, type = &quot;l&quot;, col = &quot;red&quot;) lines(x, dist_3, type = &quot;l&quot;, col = &quot;green&quot;) lines(x, dist_4, type = &quot;l&quot;, col = &quot;blue&quot;) \\[\\begin{equation} F(x) = P(X\\le x) = 1 - P(X&gt;x) \\end{equation}\\] when lower.tail == TRUE, probabiltiies are p[X&lt;x] ## density under the curve dnorm(x=0, mean=0, sd=1) dnorm(0,0,2) dnorm(0,1,1) dnorm(0,1,2) ## probability pnorm(0,0,1) pnorm(0,0,2) pnorm(0,1,1) pnorm(0,1,2) a=0 b=1 lx=100 x=seq(-4,4,length=lx) fx=dnorm(x,a,b) bx=1 dbx=dnorm(bx,a,b) plot(x,fx,type=&quot;l&quot;,lwd=2,xlab=&quot;x&quot;,ylab=&quot;Density&quot;,main=&quot;N(0,1)&quot;,las=1,xaxt=&quot;n&quot;) segments(bx,0,bx,dbx,lty=3) sx=seq(-4,bx,length=lx) polygon(c(sx,rev(sx)),c(dnorm(sx,a,b),rep(0,lx)),density=2,border=NA,lty=3) text(-0.5,0.1,expression(P(X&lt;=z[1-alpha])==1-alpha)) abline(h=0,lty=3) axis(1,at=bx,label=expression(z[1-alpha])) sx=seq(bx,4,length=lx) polygon(c(sx,rev(sx)),c(dnorm(sx,a,b),rep(0,lx)),density=3,border=NA, angle=-45,lty=3) text(2.5,0.1,expression(P(X&gt;z[1-alpha])==alpha)) Power Probability of rejecting \\(H_0\\) when it is true is type I error (falsely reject), aka significance of the test aka \\(\\alpha\\). Probability of not reject H_0 when it is false is a type II error, \\(\\beta\\). Power of test is \\(1-\\beta\\). Confidence Intervals Confidence set with a confidence coefficient of \\(1-\\alpha\\) is the set. Parametric Methods Parametric distributions with populations \\[\\begin{equation} N(\\mu, \\sigma^2),binomial(n,p) \\end{equation}\\] n=30 x=rnorm(n,mean=0,sd=1) sort(x) ## [1] -1.94791231 -1.14033164 -0.94741160 -0.88889978 -0.88239380 -0.74681654 ## [7] -0.29493245 -0.28891964 -0.24080093 -0.22370446 -0.08181749 -0.02628298 ## [13] 0.01612175 0.13046897 0.25017357 0.25168523 0.29296722 0.32067602 ## [19] 0.60273294 0.84980701 0.90581293 0.97921345 1.03703772 1.07297937 ## [25] 1.16065554 1.34259944 1.47391318 1.58196536 1.58335346 1.79003445 xbar=mean(x) sdx=sd(x) One sided H_0 \\[\\begin{equation} H_0 : \\mu = \\mu_0 vs. H_1: \\mu &gt; Mu_0\\\\ T = \\frac{\\sqrt(x-\\mu_0)}{\\sigma} \\sim \\text{t distribution with n-1 degrees of freedom} \\\\ \\text{Reject null if t} &gt; t_{n-1,1-\\alpha} \\\\ \\text{Type I error}: \\alpha = P_{\\mu_o}(T&gt;t_{n-1,1-\\alpha}) \\\\ \\text{Acceptance region} : T \\le t_{n-1,1-\\alpha}\\\\ 1- \\alpha = P_{\\mu_0}(\\frac{\\sqrt{n}(\\bar{X}-\\mu_0)}{\\hat\\sigma}) \\le t_{n-1,1-\\alpha}\\\\ = P_{\\mu_0}(\\bar{X} - t_{n-1,1-\\alpha}\\frac{\\hat\\sigma}{\\sqrt{n}} \\le \\mu_0) \\end{equation}\\] Smaller p-value, stronger evidence against H0. Critical value for alpha of 0.05 is +-1.69. The probability that mu0=1, the upper tail probability (lower.tail = F) is 0.9999, so results have a greater chance of being due to random chance than to the data itself. Alternative: that Mo0 &gt; Mu. If p was &lt;.05, then the probability we would see these results are minimal (given that it is true), so we’d accept alternative. Here, not enough chance that we’d see the alternative, so fail to reject null. alpha = 0.05 tq = qt(1-alpha, n-1) c(qt(1-alpha, n-1), qt(alpha,n-1, lower.tail = F)) ## [1] 1.699127 1.699127 mu0=1 tstat=sqrt(n)*(xbar-mu0)/sdx;c(tstat,tq,pt(tstat,n-1,lower.tail=F)) ## [1] -4.3164455 1.6991270 0.9999158 xbar-tq*sdx/sqrt(n) ## [1] -0.02516303 t.test(x,alternative=&quot;greater&quot;,mu=mu0) ## ## One Sample t-test ## ## data: x ## t = -4.3164, df = 29, p-value = 0.9999 ## alternative hypothesis: true mean is greater than 1 ## 95 percent confidence interval: ## -0.02516303 Inf ## sample estimates: ## mean of x ## 0.2643991 Smaller p-value, stronger evidence against H0. The probability that mu0=-1, the upper tail probability (lower.tail = F) is &lt;.05, so we have a lot of evidence against H0 (that these results are in the data, not due to random chance). Alternative: that Mu&gt;-1. If &lt;.05, then the probability we would see that is minimal (given that it is true), so we accept alternative, because seeing the alternative is not by chance. Here, very small probability of a result more extreme than the one actually observed if H0 is true. Since such a small probaility, given that we saw it in the data, then accept alternate. mu0=-1; tstat=sqrt(n)*(xbar-mu0)/sdx c(tstat,tq,pt(tstat,n-1, lower.tail=F)) ## [1] 7.419390e+00 1.699127e+00 1.777972e-08 xbar-tq*sdx/sqrt(n) ## [1] -0.02516303 t.test(x,alternative=&quot;greater&quot;,mu=mu0) ## ## One Sample t-test ## ## data: x ## t = 7.4194, df = 29, p-value = 1.778e-08 ## alternative hypothesis: true mean is greater than -1 ## 95 percent confidence interval: ## -0.02516303 Inf ## sample estimates: ## mean of x ## 0.2643991 Power \\[\\begin{equation} \\text{Reject null if }\\bar{X} &gt; \\mu_0 + t_{n-1,1-\\alpha}\\frac{\\hat\\sigma}{\\sqrt{n}}\\\\ \\text{Type II error: do not reject null when it is false} \\\\ \\beta = P_{H_1}\\text{do not reject null}\\\\ \\text{Power: the probability of rejecting null when alt is true}\\\\ 1-\\beta = P_{\\mu}(\\bar{X} &gt; \\mu_0 + t_{n-1,1-\\alpha}\\frac{\\hat\\sigma}{\\sqrt{n}}) \\\\ = P_{\\mu}(\\frac{\\sqrt{n}(X-\\mu)}{\\hat\\sigma} &gt; \\frac{\\sqrt{n}(\\mu_0 -\\mu)}{\\hat\\sigma} + t_{n-1,1-\\alpha} \\end{equation}\\] alpha = 0.05 tq = qt(1-alpha, n-1) mu0=1 mu=1.5 tv = sqrt(n)*(mu0-mu)/sdx+tq pt(tv,n-1,lower.tail=F) ## [1] 0.8865975 power.t.test(n,delta = abs(mu0-mu), sd=sdx, type = c(&quot;one.sample&quot;), alternative = &quot;one.sided&quot;) ## ## One-sample t test power calculation ## ## n = 30 ## delta = 0.5 ## sd = 0.9334189 ## sig.level = 0.05 ## power = 0.888687 ## alternative = one.sided \\[\\begin{equation} t_{n-1,\\beta} = \\frac{\\sqrt{n}(\\mu_0 - \\mu)}{\\hat\\sigma} + t_{n-1,1-\\alpha}\\\\ n = [\\frac{\\hat\\sigma(t_{n-1,\\beta}-t_{n-1,1-\\alpha})}{\\mu_0-\\mu}]^2 \\end{equation}\\] beta =0.1 tb = qt(beta, n-1) (sdx*(tb-tq)/(mu0-mu))^2 ## [1] 31.58697 power.t.test(power= 0.9, delta = abs(mu0-mu), sd = sdx, type = c(&quot;one.sample&quot;), alternative = &quot;one.sided&quot;) ## ## One-sample t test power calculation ## ## n = 31.24942 ## delta = 0.5 ## sd = 0.9334189 ## sig.level = 0.05 ## power = 0.9 ## alternative = one.sided Two sided H1 \\[\\begin{equation} H_0 : \\mu = \\mu_0 vs. H_1: \\mu &gt; Mu_0\\\\ \\text{Reject null if |T|} &gt; t_{n-1,1-\\frac{\\alpha}{2}} \\\\ \\text{Acceptance region} : \\frac{\\sqrt{n}\\mid{\\bar{X} - \\mu_0}\\mid}{\\hat\\sigma} \\le t_{n-1,1-\\frac{\\alpha}{2}}\\\\ 1- \\alpha = P_{\\mu_0}(\\frac{\\sqrt{n}(\\bar{X}-\\mu_0)}{\\hat\\sigma}) \\le t_{n-1,1-\\frac{\\alpha}{2}}\\\\ = P_{\\mu_0}(\\bar{X} - t_{n-1,1-\\frac{\\alpha}{2}}\\frac{\\hat\\sigma}{\\sqrt{n}} \\le \\mu_0 \\le \\bar{X} + t_{n-1,1-\\frac{\\alpha}{2}}\\frac{\\hat\\sigma}{\\sqrt{n}}) \\\\ \\text{Length of CI} : 2t_{n-1,1-\\frac{\\alpha}{2}}\\frac{\\hat\\sigma}{\\sqrt{n}} \\end{equation}\\] alpha = 0.05 tq = qt(1-alpha/2, n-1) mu0=0 tstat = sqrt(n)*(xbar-mu0)/sdx c(tstat, tq,2*pt(abs(tstat),n-1, lower.tail =F)) ## [1] 1.5514724 2.0452296 0.1316346 xbar+c(-1,1)*tq*sdx/sqrt(n) ## [1] -0.08414522 0.61294348 t.test(x,mu=mu0) ## ## One Sample t-test ## ## data: x ## t = 1.5515, df = 29, p-value = 0.1316 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -0.08414522 0.61294348 ## sample estimates: ## mean of x ## 0.2643991 mu0=1 tstat=sqrt(n)*(xbar-mu0)/sdx c(tstat,tq,2*pt(abs(tstat),n-1,lower.tail = F)) ## [1] -4.316445533 2.045229642 0.000168423 xbar + c(-1,1)*tq*sdx/sqrt(n) ## [1] -0.08414522 0.61294348 t.test(x,mu=mu0) ## ## One Sample t-test ## ## data: x ## t = -4.3164, df = 29, p-value = 0.0001684 ## alternative hypothesis: true mean is not equal to 1 ## 95 percent confidence interval: ## -0.08414522 0.61294348 ## sample estimates: ## mean of x ## 0.2643991 Power alpha = 0.05; tq = qt(1-alpha/2,n-1);mu0=1; mu=1.5; tv0=sqrt(n)*(mu0-mu)/sdx; pt(tv0+tq,n-1,lower.tail=F) + pt(tv0-tq,n-1); ## [1] 0.8092828 power.t.test(n,delta=abs(mu0-mu), sd=sdx, type = c(&quot;one.sample&quot;),alternative=&quot;two.sided&quot;) ## ## One-sample t test power calculation ## ## n = 30 ## delta = 0.5 ## sd = 0.9334189 ## sig.level = 0.05 ## power = 0.8093807 ## alternative = two.sided power.t.test(n,delta=abs(mu0-mu),sd=sdx, type =c(&quot;one.sample&quot;),alternative=&quot;two.sided&quot;,strict=T) ## ## One-sample t test power calculation ## ## n = 30 ## delta = 0.5 ## sd = 0.9334189 ## sig.level = 0.05 ## power = 0.8093815 ## alternative = two.sided "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
